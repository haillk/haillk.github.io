<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>python on Haillk</title>
    <link>https://haillk.github.io/tags/python/</link>
    <description>Recent content in python on Haillk</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Sat, 14 Dec 2019 22:21:47 +0800</lastBuildDate>
    
	<atom:link href="https://haillk.github.io/tags/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Scrapy常用命令</title>
      <link>https://haillk.github.io/2019/12/scrapy%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Sat, 14 Dec 2019 22:21:47 +0800</pubDate>
      
      <guid>https://haillk.github.io/2019/12/scrapy%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</guid>
      <description>新建一个工程 scrapy startproject spider_name 构建爬虫 scrapy genspider name domain 运行爬虫 scrapy runspider 爬虫名称 启动项目 scrapy crawl xxx</description>
    </item>
    
    <item>
      <title>Anaconda常用命令</title>
      <link>https://haillk.github.io/2019/12/anaconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Sat, 14 Dec 2019 22:02:22 +0800</pubDate>
      
      <guid>https://haillk.github.io/2019/12/anaconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</guid>
      <description>查看虚拟环境 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ##创建虚拟环境 conda create -n env-name python=X.X ##切换虚拟环境 conda activate env-name ##关闭虚拟环境 deactivate ##删除虚拟环境 conda remove -n env-name --all ##查看</description>
    </item>
    
    <item>
      <title>Anaconda常用命令</title>
      <link>https://haillk.github.io/2019/12/anaconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Sat, 14 Dec 2019 22:02:22 +0800</pubDate>
      
      <guid>https://haillk.github.io/2019/12/anaconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</guid>
      <description>查看虚拟环境 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ##创建虚拟环境 conda create -n env-name python=X.X ##切换虚拟环境 conda activate env-name ##关闭虚拟环境 deactivate ##删除虚拟环境 conda remove -n env-name --all ##查看</description>
    </item>
    
    <item>
      <title>Windows通过pip安装scrapy</title>
      <link>https://haillk.github.io/2019/12/windows%E5%AE%89%E8%A3%85scrapy/</link>
      <pubDate>Tue, 10 Dec 2019 18:29:22 +0800</pubDate>
      
      <guid>https://haillk.github.io/2019/12/windows%E5%AE%89%E8%A3%85scrapy/</guid>
      <description>Windows通过pip安装scrapy Scrapy需要超多的依赖，而pip instarll scrapy并不会下载好全部依赖。我在安装twisted时出现</description>
    </item>
    
  </channel>
</rss>