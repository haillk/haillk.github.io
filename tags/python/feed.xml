<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>python on Haillk-Blog</title>
    <link>https://haillk.github.io/tags/python/</link>
    <description>Recent content in python on Haillk-Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Fri, 27 Dec 2019 02:15:34 +0800</lastBuildDate>
    
	<atom:link href="https://haillk.github.io/tags/python/feed.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Yield完全解读</title>
      <link>https://haillk.github.io/post/python/yield%E5%AE%8C%E5%85%A8%E8%A7%A3%E8%AF%BB/</link>
      <pubDate>Fri, 27 Dec 2019 02:15:34 +0800</pubDate>
      
      <guid>https://haillk.github.io/post/python/yield%E5%AE%8C%E5%85%A8%E8%A7%A3%E8%AF%BB/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Scrapy常用命令</title>
      <link>https://haillk.github.io/post/python/scrapy%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Sat, 14 Dec 2019 22:21:47 +0800</pubDate>
      
      <guid>https://haillk.github.io/post/python/scrapy%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</guid>
      <description>新建一个工程 scrapy startproject spider_name 构建爬虫 scrapy genspider name domain 运行爬虫 scrapy runspider 爬虫名称 启动项目 scrapy crawl xxx</description>
    </item>
    
    <item>
      <title>Anaconda常用命令</title>
      <link>https://haillk.github.io/post/python/anaconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Sat, 14 Dec 2019 22:02:22 +0800</pubDate>
      
      <guid>https://haillk.github.io/post/python/anaconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</guid>
      <description>查看虚拟环境 ##创建虚拟环境 conda create -n env-name python=X.X ##切换虚拟环境 conda activate env-name ##关闭虚拟环境 deactivate ##删除虚拟环境 conda remove -n env-name --all ##查看存在的虚拟环境 conda env list 包管理 #</description>
    </item>
    
    <item>
      <title>Windows通过pip安装scrapy</title>
      <link>https://haillk.github.io/post/python/windows%E5%AE%89%E8%A3%85scrapy/</link>
      <pubDate>Tue, 10 Dec 2019 18:29:22 +0800</pubDate>
      
      <guid>https://haillk.github.io/post/python/windows%E5%AE%89%E8%A3%85scrapy/</guid>
      <description>Windows通过pip安装scrapy Scrapy需要超多的依赖，而pip instarll scrapy并不会下载好全部依赖。我在安装twisted时出现</description>
    </item>
    
  </channel>
</rss>