<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on Haillk</title>
    <link>https://haillk.github.io/categories/python/</link>
    <description>Recent content in Python on Haillk</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Sun, 15 Dec 2019 00:49:02 +0800</lastBuildDate>
    
	<atom:link href="https://haillk.github.io/categories/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Selenium安装使用</title>
      <link>https://haillk.github.io/2019/12/selenium%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Sun, 15 Dec 2019 00:49:02 +0800</pubDate>
      
      <guid>https://haillk.github.io/2019/12/selenium%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/</guid>
      <description>selenium能真是的模拟打开一个浏览器，模拟鼠标事件，提供选择器，控制cookie等等。 安装 由于使用了conda,安装就很方便了。 conda install selenium</description>
    </item>
    
    <item>
      <title>Scrapy常用命令</title>
      <link>https://haillk.github.io/2019/12/scrapy%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Sat, 14 Dec 2019 22:21:47 +0800</pubDate>
      
      <guid>https://haillk.github.io/2019/12/scrapy%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</guid>
      <description>新建一个工程 scrapy startproject spider_name 构建爬虫 scrapy genspider name domain 运行爬虫 scrapy runspider 爬虫名称 启动项目 scrapy crawl xxx</description>
    </item>
    
    <item>
      <title>Anaconda常用命令</title>
      <link>https://haillk.github.io/2019/12/anaconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Sat, 14 Dec 2019 22:02:22 +0800</pubDate>
      
      <guid>https://haillk.github.io/2019/12/anaconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</guid>
      <description>查看虚拟环境 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ##创建虚拟环境 conda create -n env-name python=X.X ##切换虚拟环境 conda activate env-name ##关闭虚拟环境 deactivate ##删除虚拟环境 conda remove -n env-name --all ##查看</description>
    </item>
    
    <item>
      <title>Anaconda常用命令</title>
      <link>https://haillk.github.io/2019/12/anaconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Sat, 14 Dec 2019 22:02:22 +0800</pubDate>
      
      <guid>https://haillk.github.io/2019/12/anaconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</guid>
      <description>查看虚拟环境 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ##创建虚拟环境 conda create -n env-name python=X.X ##切换虚拟环境 conda activate env-name ##关闭虚拟环境 deactivate ##删除虚拟环境 conda remove -n env-name --all ##查看</description>
    </item>
    
    <item>
      <title>Windows通过pip安装scrapy</title>
      <link>https://haillk.github.io/2019/12/windows%E5%AE%89%E8%A3%85scrapy/</link>
      <pubDate>Tue, 10 Dec 2019 18:29:22 +0800</pubDate>
      
      <guid>https://haillk.github.io/2019/12/windows%E5%AE%89%E8%A3%85scrapy/</guid>
      <description>Windows通过pip安装scrapy Scrapy需要超多的依赖，而pip instarll scrapy并不会下载好全部依赖。我在安装twisted时出现</description>
    </item>
    
    <item>
      <title>安装更新pip</title>
      <link>https://haillk.github.io/2019/12/%E5%AE%89%E8%A3%85%E6%9B%B4%E6%96%B0pip/</link>
      <pubDate>Tue, 10 Dec 2019 18:01:37 +0800</pubDate>
      
      <guid>https://haillk.github.io/2019/12/%E5%AE%89%E8%A3%85%E6%9B%B4%E6%96%B0pip/</guid>
      <description>ModuleNotFoundError: No module named &amp;lsquo;pip&amp;rsquo; 可以首先执行 python -m ensurepip 然后执行 python -m pip install --upgrade pip 即可更新完毕。</description>
    </item>
    
    <item>
      <title>Debian安装python38</title>
      <link>https://haillk.github.io/2019/12/debian%E5%AE%89%E8%A3%85python38/</link>
      <pubDate>Sat, 07 Dec 2019 22:19:52 +0800</pubDate>
      
      <guid>https://haillk.github.io/2019/12/debian%E5%AE%89%E8%A3%85python38/</guid>
      <description>源码安装 1、安装依赖包 1 sudo apt-get install build-essential python-dev python-setuptools python-pip python-smbus build-essential libncursesw5-dev libgdbm-dev libc6-dev zlib1g-dev libsqlite3-dev tk-dev libssl-dev openssl libffi-dev 2、下载python3.8源码 1 2 3 4 5 6 7 ##更新 sudo apt-get update ##下载 wget https://www.python.org/downloads/release/python-380/ ##解压 tar</description>
    </item>
    
    <item>
      <title>流畅的python学习笔记 2</title>
      <link>https://haillk.github.io/2019/12/%E6%B5%81%E7%95%85%E7%9A%84python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-2/</link>
      <pubDate>Sat, 07 Dec 2019 00:40:52 +0800</pubDate>
      
      <guid>https://haillk.github.io/2019/12/%E6%B5%81%E7%95%85%E7%9A%84python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-2/</guid>
      <description>1、列表推导 列表循环：dummy = [ord(symbol) for symbol in symbols] 传统for循环： 1 2 for symbol in symbols: ... codes.append(ord(symbol)) 带条件的列表推导：beyond_ascii = [ord(s) for s in symbols if ord(s) &amp;gt; 127] 笛</description>
    </item>
    
    <item>
      <title>流畅的python学习笔记 1</title>
      <link>https://haillk.github.io/2019/12/%E6%B5%81%E7%95%85%E7%9A%84python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/</link>
      <pubDate>Fri, 06 Dec 2019 01:43:47 +0800</pubDate>
      
      <guid>https://haillk.github.io/2019/12/%E6%B5%81%E7%95%85%E7%9A%84python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/</guid>
      <description>特殊方法的格式 特殊方法的名字以两个下划线开头,两个下划线结尾(例如_getitem_)。比如 obj[key] 的背后就是 getitem 方法， 为了能求得 my_collection[key] 的值， 解释器实际</description>
    </item>
    
  </channel>
</rss>